{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from joblib import dump\n",
    "from collections import Counter\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import *\n",
    "from joblib import load\n",
    "from aqosd_experiments.config import *\n",
    "from aqosd_experiments.data import *\n",
    "from aqosd_experiments.utils import *\n",
    "from aqosd_experiments.plot import *\n",
    "from aqosd_experiments.scorers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 23:59:50 of Data\n",
      "Shape of metrics :  (8640, 104) \t Shape of bottlenecks :  (8640, 32)\n",
      "Label cardinality = 1.96019 \t Label density = 0.06126\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics, bottlenecks = import_and_prepare_data(RAW_DATASET_PATH,  HOST_LIST)\n",
    "print('Shape of metrics : ',metrics.shape,'\\t','Shape of bottlenecks : ',bottlenecks.shape)\n",
    "print('Label cardinality = %.5f \\t Label density = %.5f' % (bottlenecks.sum(axis=1).mean(),bottlenecks.mean(axis=1).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SRV./: Free inodes in %', 'SRV./: Space utilization', 'SRV./: Used space', 'SRV./boot: Free inodes in %', 'SRV./boot: Space utilization', 'SRV./boot: Used space', 'SRV.Available memory', 'SRV.Available memory in %', 'SRV.CPU idle time', 'SRV.CPU iowait time', 'SRV.CPU softirq time', 'SRV.CPU system time', 'SRV.CPU user time', 'SRV.CPU utilization', 'SRV.Context switches per second', 'SRV.Free swap space', 'SRV.Free swap space in %', 'SRV.Interface enp0s8: Bits received', 'SRV.Interface enp0s8: Bits sent', 'SRV.Interrupts per second', 'SRV.Load average (15m avg)', 'SRV.Load average (1m avg)', 'SRV.Load average (5m avg)', 'SRV.Memory utilization', 'SRV.Number of processes', 'SRV.Number of running processes', 'GW1./: Free inodes in %', 'GW1./: Space utilization', 'GW1./: Used space', 'GW1./boot: Free inodes in %', 'GW1./boot: Space utilization', 'GW1./boot: Used space', 'GW1.Available memory', 'GW1.Available memory in %', 'GW1.CPU idle time', 'GW1.CPU iowait time', 'GW1.CPU softirq time', 'GW1.CPU system time', 'GW1.CPU user time', 'GW1.CPU utilization', 'GW1.Context switches per second', 'GW1.Free swap space', 'GW1.Free swap space in %', 'GW1.Interface enp0s8: Bits received', 'GW1.Interface enp0s8: Bits sent', 'GW1.Interrupts per second', 'GW1.Load average (15m avg)', 'GW1.Load average (1m avg)', 'GW1.Load average (5m avg)', 'GW1.Memory utilization', 'GW1.Number of processes', 'GW1.Number of running processes', 'GW11./: Free inodes in %', 'GW11./: Space utilization', 'GW11./: Used space', 'GW11./boot: Free inodes in %', 'GW11./boot: Space utilization', 'GW11./boot: Used space', 'GW11.Available memory', 'GW11.Available memory in %', 'GW11.CPU idle time', 'GW11.CPU iowait time', 'GW11.CPU softirq time', 'GW11.CPU system time', 'GW11.CPU user time', 'GW11.CPU utilization', 'GW11.Context switches per second', 'GW11.Free swap space', 'GW11.Free swap space in %', 'GW11.Interface enp0s8: Bits received', 'GW11.Interface enp0s8: Bits sent', 'GW11.Interrupts per second', 'GW11.Load average (15m avg)', 'GW11.Load average (1m avg)', 'GW11.Load average (5m avg)', 'GW11.Memory utilization', 'GW11.Number of processes', 'GW11.Number of running processes', 'GW111./: Free inodes in %', 'GW111./: Space utilization', 'GW111./: Used space', 'GW111./boot: Free inodes in %', 'GW111./boot: Space utilization', 'GW111./boot: Used space', 'GW111.Available memory', 'GW111.Available memory in %', 'GW111.CPU idle time', 'GW111.CPU iowait time', 'GW111.CPU softirq time', 'GW111.CPU system time', 'GW111.CPU user time', 'GW111.CPU utilization', 'GW111.Context switches per second', 'GW111.Free swap space', 'GW111.Free swap space in %', 'GW111.Interface enp0s8: Bits received', 'GW111.Interface enp0s8: Bits sent', 'GW111.Interrupts per second', 'GW111.Load average (15m avg)', 'GW111.Load average (1m avg)', 'GW111.Load average (5m avg)', 'GW111.Memory utilization', 'GW111.Number of processes', 'GW111.Number of running processes']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['GW1.cpu', 'GW1.diskio', 'GW1.diskspace', 'GW1.memory', 'GW1.network delay', 'GW1.network packet corrupt', 'GW1.network packet duplicate', 'GW1.network packet loss', 'GW11.cpu', 'GW11.diskio', 'GW11.diskspace', 'GW11.memory', 'GW11.network delay', 'GW11.network packet corrupt', 'GW11.network packet duplicate', 'GW11.network packet loss', 'GW111.cpu', 'GW111.diskio', 'GW111.diskspace', 'GW111.memory', 'GW111.network delay', 'GW111.network packet corrupt', 'GW111.network packet duplicate', 'GW111.network packet loss', 'SRV.cpu', 'SRV.diskio', 'SRV.diskspace', 'SRV.memory', 'SRV.network delay', 'SRV.network packet corrupt', 'SRV.network packet duplicate', 'SRV.network packet loss']\n"
     ]
    }
   ],
   "source": [
    "metric_names, bottleneck_names = list(metrics.columns), list(bottlenecks.columns)\n",
    "print(metric_names)\n",
    "print(100*'-')\n",
    "print(bottleneck_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes, test_indexes = next(CV_2.split(metrics, bottlenecks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6480, 104), (6480, 32), (2160, 104), (2160, 32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = metrics.iloc[train_indexes, :], bottlenecks.iloc[train_indexes, :]\n",
    "X_test, y_test = metrics.iloc[test_indexes, :], bottlenecks.iloc[test_indexes, :]\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6480, 104), (6480, 32), (2160, 104), (2160, 32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = X_train.values, y_train.values,  X_test.values, y_test.values\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(4, 4)</th>\n",
       "      <th>(4, 15)</th>\n",
       "      <th>(15, 15)</th>\n",
       "      <th>(30, 30)</th>\n",
       "      <th>(15, 30)</th>\n",
       "      <th>(23, 23)</th>\n",
       "      <th>(23, 30)</th>\n",
       "      <th>(27, 30)</th>\n",
       "      <th>(27, 27)</th>\n",
       "      <th>(1, 1)</th>\n",
       "      <th>...</th>\n",
       "      <th>(16, 28)</th>\n",
       "      <th>(14, 28)</th>\n",
       "      <th>(5, 24)</th>\n",
       "      <th>(0, 23)</th>\n",
       "      <th>(5, 26)</th>\n",
       "      <th>(1, 7)</th>\n",
       "      <th>(13, 30)</th>\n",
       "      <th>(6, 30)</th>\n",
       "      <th>(7, 31)</th>\n",
       "      <th>(9, 23)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>412.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>138.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       (4, 4)  (4, 15)  (15, 15)  (30, 30)  (15, 30)  (23, 23)  (23, 30)  \\\n",
       "train   412.0     16.0     291.0     332.0      21.0     257.0      11.0   \n",
       "test    138.0      5.0     101.0     120.0       7.0      86.0       4.0   \n",
       "\n",
       "       (27, 30)  (27, 27)  (1, 1)  ...  (16, 28)  (14, 28)  (5, 24)  (0, 23)  \\\n",
       "train      46.0     528.0   350.0  ...      14.0       4.0      9.0      5.0   \n",
       "test       15.0     179.0   124.0  ...       5.0       2.0      3.0      1.0   \n",
       "\n",
       "       (5, 26)  (1, 7)  (13, 30)  (6, 30)  (7, 31)  (9, 23)  \n",
       "train      5.0     9.0       9.0      2.0      5.0      4.0  \n",
       "test       2.0     0.0       3.0      1.0      2.0      2.0  \n",
       "\n",
       "[2 rows x 501 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'train': Counter(str(c) for row in get_combination_wise_output_matrix(y_train, order=2) for c in row),\n",
    "    'test' : Counter(str(c) for row in get_combination_wise_output_matrix(y_test, order=2) for c in row)\n",
    "}).T.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_roc_auc(clf_name, y_score, y_test, labels):\n",
    "    fig, ax = plt.subplots(figsize=(1.5, 1.5))\n",
    "    if not hasattr(y_score, 'toarray'):\n",
    "        y_score = np.array(y_score).T[1] if isinstance(y_score, list)  else np.array(y_score)\n",
    "    if hasattr(y_score, 'A'):\n",
    "        y_score = y_score.A\n",
    "    n_classes, lw = len(labels), 1\n",
    "    fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    fpr[\"macro\"], tpr[\"macro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    min_class = min(roc_auc, key=roc_auc.get)\n",
    "    max_class = max(roc_auc, key=roc_auc.get)\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], color='grey', label='Bottleneck curve[1-'+str(n_classes)+']', alpha=.5,linestyle='solid',\n",
    "                lw=.5) if i == 0 else ax.plot(fpr[i], tpr[i], color='grey', alpha=.5, lw=.5, linestyle='solid')\n",
    "    ax.plot(fpr[\"macro\"], tpr[\"samples\"], label='Average area={0:0.3f}' ''.format(roc_auc[\"macro\"]), color='r', \n",
    "            linewidth=lw, linestyle='-')\n",
    "    ax.plot(fpr[min_class], tpr[min_class], label='Minimum area={0:0.3f}' ''.format(roc_auc[min_class]), color='b', \n",
    "            linewidth=lw, linestyle='--')\n",
    "    ax.plot([0, 1], [0, 1], color='g', lw=.5, linestyle='--', label='Random Classifier')\n",
    "    ax.set_xlim([-0.05, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('1 - Specificity')\n",
    "    ax.set_ylabel('Sensitivity')\n",
    "    ax.legend(loc='lower right', fontsize=5.5)\n",
    "    [item.set_fontsize(5) for item in ([ax.title,ax.xaxis.label,ax.yaxis.label]+ax.get_xticklabels()+ax.get_yticklabels())]\n",
    "    #ax.set_title(clf_name)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def print_metrics(y_test, y_pred):\n",
    "    a = accuracy_score(y_test, y_pred)\n",
    "    c = coverage_error(y_test, y_pred)\n",
    "    p = precision_score(y_test, y_pred, average=AVERAGE)\n",
    "    s = user_defined_specificity(y_test, y_pred)\n",
    "    r = recall_score(y_test, y_pred, average=AVERAGE)\n",
    "    rest = {'Precision':round(p, ROUND), 'Subset Accuracy': round(a, ROUND), 'Coverage Error':round(c, ROUND),\n",
    "           'Specificity':round(s, ROUND),'Sensitivity':round(r, ROUND)}\n",
    "    print('\\t',rest)\n",
    "    return rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, results_y_pred, results_y_pred_proba={},{},{}\n",
    "def train(X_train, y_train, X_test, y_test):\n",
    "    for clf_name, clf in CLASSIFIERS.items():\n",
    "        train_x, train_y = np.copy(X_train), np.copy(y_train)\n",
    "        test_x, test_y = np.copy(X_test), np.copy(y_test)\n",
    "        print(80*'-')\n",
    "        print('#',clf_name.ljust(16), end=' ')\n",
    "        start=time.time()\n",
    "        clf.fit(train_x, train_y);\n",
    "        fit_time = round(time.time()-start, ROUND)\n",
    "        print('>','fit_time:',fit_time,'secondes', end = ' ')\n",
    "        start=time.time()\n",
    "        y_pred = clf.predict(test_x)\n",
    "        predict_time=  round(time.time()-start, ROUND)\n",
    "        print('>','predict_time:',predict_time,'secondes')\n",
    "        results_y_pred_proba[clf_name] = clf.predict_proba(test_x)\n",
    "        if not hasattr(y_pred, 'toarray'):\n",
    "            y_pred = sparse.csr_matrix(y_pred)\n",
    "        results_y_pred[clf_name] = y_pred\n",
    "        results[clf_name] = print_metrics(test_y, y_pred.toarray())\n",
    "        results[clf_name]['Fit Time']=fit_time\n",
    "        results[clf_name]['Predict Time']=predict_time\n",
    "    return pd.DataFrame.from_dict(results)\n",
    "def plot(results_y_pred_proba, y_test):\n",
    "    for clf_name, clf in CLASSIFIERS.items():\n",
    "        y_pred_proba = results_y_pred_proba[clf_name]\n",
    "        fig = plt_roc_auc(clf_name, y_pred_proba, y_test, bottleneck_names)\n",
    "        fig.savefig(FIG_PATH + clf_name +\"_roc_curve.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "# CC [Neural Net]  > fit_time: 132.9161 secondes > predict_time: 0.3038 secondes\n",
      "\t {'Precision': 0.8671, 'Subset Accuracy': 0.5602, 'Coverage Error': 12.0782, 'Specificity': 0.992, 'Sensitivity': 0.7831}\n",
      "--------------------------------------------------------------------------------\n",
      "# BR [Neural Net]  > fit_time: 128.4111 secondes > predict_time: 0.2394 secondes\n",
      "\t {'Precision': 0.8753, 'Subset Accuracy': 0.538, 'Coverage Error': 12.6736, 'Specificity': 0.9926, 'Sensitivity': 0.778}\n",
      "--------------------------------------------------------------------------------\n",
      "# LP [Neural Net]  > fit_time: 67.8486 secondes > predict_time: 0.2703 secondes\n",
      "\t {'Precision': 0.8253, 'Subset Accuracy': 0.6519, 'Coverage Error': 9.394, 'Specificity': 0.9887, 'Sensitivity': 0.8307}\n",
      "--------------------------------------------------------------------------------\n",
      "# ML-kNN           > fit_time: 13.7581 secondes > predict_time: 4.6626 secondes\n",
      "\t {'Precision': 0.8388, 'Subset Accuracy': 0.5167, 'Coverage Error': 13.6213, 'Specificity': 0.9904, 'Sensitivity': 0.7515}\n"
     ]
    }
   ],
   "source": [
    "df = train(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC [Neural Net]</th>\n",
       "      <th>BR [Neural Net]</th>\n",
       "      <th>LP [Neural Net]</th>\n",
       "      <th>ML-kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.8671</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>0.8253</td>\n",
       "      <td>0.8388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset Accuracy</th>\n",
       "      <td>0.5602</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.6519</td>\n",
       "      <td>0.5167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coverage Error</th>\n",
       "      <td>12.0782</td>\n",
       "      <td>12.6736</td>\n",
       "      <td>9.3940</td>\n",
       "      <td>13.6213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9887</td>\n",
       "      <td>0.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.7831</td>\n",
       "      <td>0.7780</td>\n",
       "      <td>0.8307</td>\n",
       "      <td>0.7515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fit Time</th>\n",
       "      <td>132.9161</td>\n",
       "      <td>128.4111</td>\n",
       "      <td>67.8486</td>\n",
       "      <td>13.7581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predict Time</th>\n",
       "      <td>0.3038</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>4.6626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CC [Neural Net]  BR [Neural Net]  LP [Neural Net]   ML-kNN\n",
       "Precision                 0.8671           0.8753           0.8253   0.8388\n",
       "Subset Accuracy           0.5602           0.5380           0.6519   0.5167\n",
       "Coverage Error           12.0782          12.6736           9.3940  13.6213\n",
       "Specificity               0.9920           0.9926           0.9887   0.9904\n",
       "Sensitivity               0.7831           0.7780           0.8307   0.7515\n",
       "Fit Time                132.9161         128.4111          67.8486  13.7581\n",
       "Predict Time              0.3038           0.2394           0.2703   4.6626"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(results_y_pred_proba, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "d, lw=8, .5\n",
    "c = cycle(['k','r','b','g'][::-1])\n",
    "mpl.rcParams['hatch.linewidth'] = 0.1 \n",
    "h1, h2 = 8, 3\n",
    "hatchs=cycle([h1*\"*\",h1*\"/\", h1*\"+\",h1*\"x\", h2*\"/\", h2*\"+\",h2*\"x\",\"\"][::-1])  \n",
    "boxprops = dict(linestyle='-', linewidth=lw)\n",
    "flierprops = dict(marker='o', markerfacecolor='w', markersize=2, markeredgewidth=lw)\n",
    "medianprops = dict(linestyle='-', linewidth=lw, color='r')\n",
    "meanlineprops = dict(linestyle='-', linewidth=lw)\n",
    "meanpointprops = dict(marker=\">\", markeredgecolor='none', markerfacecolor='b',markersize=4)\n",
    "whiskerprops = dict(linestyle='-' , linewidth=lw)\n",
    "\n",
    "def plt_precision_box(y_score, y_test, labels):\n",
    "    def add_hatch(bp):\n",
    "        for box in  bp['boxes']:\n",
    "            cs=next(c)\n",
    "            box.set(facecolor = \"w\" )\n",
    "            box.set(hatch =next(hatchs))\n",
    "        for cap in bp['caps']:\n",
    "            cap.set(linewidth=.5)\n",
    "    def getdf(df0, cl):\n",
    "        df = df0.groupby(cl)['precision'].apply(list).to_frame().T\n",
    "        df = df.apply(pd.Series.explode)\n",
    "        df.reset_index(inplace=True)\n",
    "        del df['index']\n",
    "        df = df.rename_axis(None, axis = 1)\n",
    "        for c in df.columns:\n",
    "            df[c] = df[c].astype(float) \n",
    "        return df\n",
    "\n",
    "    figs=[]\n",
    "    _precision={}\n",
    "    if not hasattr(y_score, 'toarray'):\n",
    "        y_score = np.array(y_score).T[1] if isinstance(y_score, list)  else np.array(y_score)\n",
    "    if hasattr(y_score, 'A'):\n",
    "        y_score = y_score.A\n",
    "    for i in range(len(labels)):\n",
    "        _precision[labels[i]] = precision_score(y_test[:, i], y_score[:, i])\n",
    "    df = pd.DataFrame.from_dict(_precision, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df[\"Node\"], df[\"Bottleneck\"] = zip(*df['index'].str.split('.').tolist())\n",
    "    del df['index']\n",
    "    df.columns=['precision', 'Node', 'Bottleneck']\n",
    "    df = df[['Node','Bottleneck', 'precision']]\n",
    "    \n",
    "    groups=['Node', 'Bottleneck']\n",
    "    for i, cl in enumerate(groups):\n",
    "        df1= getdf(df, cl)\n",
    "        f, ax = plt.subplots(figsize=(1.6, 1.6))\n",
    "        if i==0:\n",
    "            cols=[\"SRV\", \"GW1\", \"GW11\",\"GW111\"][::-1]\n",
    "            lab=[\"NF1\", \"NF2\", \"NF3\", \"NF4\"][::-1]\n",
    "        else :\n",
    "            cols=['cpu','memory','diskspace','diskio','network delay','network packet duplicate','network packet loss',\n",
    "                  'network packet corrupt'][::-1]\n",
    "            lab=['CPU','Memory','Disk space','Disk I/O','Packet delay','Packet duplicate','Packet loss',\n",
    "                 'Packet corrupt'][::-1]\n",
    "        df1 = df1[cols]\n",
    "        df1.columns=lab\n",
    "        df2=pd.DataFrame()\n",
    "        df2['mean']=df1.mean()\n",
    "        df2['min']=df1.min()\n",
    "        df2['median']=df1.median()\n",
    "        #display(df2.mean())\n",
    "        boxplot  = df1.boxplot(ax=ax,  rot=0, fontsize=5,  patch_artist=True, return_type='dict', vert=False,\n",
    "                               boxprops=boxprops,flierprops=flierprops, medianprops=medianprops,showmeans=True,\n",
    "                               meanprops=meanpointprops , whiskerprops=whiskerprops)\n",
    "        #ax.set_xlim(0.7,1)\n",
    "        add_hatch(boxplot)\n",
    "        figs.append(f)\n",
    "    return figs, groups\n",
    "\n",
    "figs, groups = plt_precision_box(results_y_pred['LP [Neural Net]'], y_test, bottleneck_names)\n",
    "_ = [f.savefig(FIG_PATH +group+\"_resultat.pdf\", bbox_inches='tight') for f, group in zip(figs, groups)]\n",
    "print(np.mean(precision_score(y_test,results_y_pred['LP [Neural Net]'],  average=None)))\n",
    "print(np.mean(precision_score(y_test,results_y_pred['LP [Neural Net]'],  average='macro')))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
