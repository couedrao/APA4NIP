{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext watermark\n",
    "#%watermark -a 'Ouedraogo Clovis' -u -d -v -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import dump\n",
    "\n",
    "from aqosd_experiments.config import *\n",
    "from aqosd_experiments.data import *\n",
    "from aqosd_experiments.plot import *\n",
    "from aqosd_experiments.scorers import *\n",
    "from osms import OverheadSensitiveMetricSelection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable             Type           Data/Info\n",
      "---------------------------------------------\n",
      "AVERAGE              str            samples\n",
      "CLASSIFIERS          OrderedDict    OrderedDict([('Random Cla<...>re_dense=[True, True]))])\n",
      "CLEAN_DATASET_PATH   str            C:/Users/couedrao/Pycharm<...>ts/../data/clean_dataset/\n",
      "DATE_FORMAT          str            %Y-%m-%d %H:%M:%S\n",
      "FIG_PATH             str            C:/Users/couedrao/Pycharm<...>/../data/output/plotting/\n",
      "HOST_LIST            tuple          n=4\n",
      "K_FOLD               int            3\n",
      "MODELS_PATH          str            C:/Users/couedrao/Pycharm<...>data/output/saved_models/\n",
      "PATH                 str            C:/Users/couedrao/Pycharm<...>qosd_experiments/../data/\n",
      "RAW_DATASET_PATH     str            C:/Users/couedrao/Pycharm<...>ents/../data/raw_dataset/\n",
      "ROUND                int            5\n",
      "SCORING              OrderedDict    OrderedDict([('mcc', make<...>scorer(accuracy_score))])\n",
      "SEED                 int            42\n"
     ]
    }
   ],
   "source": [
    "%whos str  int  tuple OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#raw_dataset_path, host_list, models_path, fig_path= RAW_DATASET_PATH,  HOST_LIST, MODELS_PATH, FIG_PATH\n",
    "#classifiers,param_grids = CLASSIFIERS, PARAM_GRIDS\n",
    "#scoring, cv = SCORING, CV\n",
    "save=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fig = plt_long_stats(RAW_DATASET_PATH, HOST_LIST)\n",
    "if save:\n",
    "    fig.savefig(fig_path + \"Sample.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of metrics :  (38814, 104) \t Shape of bottlenecks :  (38814, 32)\n",
      "Label cardinality = 2.02118 \t Label density = 0.06316\n"
     ]
    }
   ],
   "source": [
    "metrics, bottlenecks = import_and_prepare_data(RAW_DATASET_PATH, HOST_LIST)\n",
    "print('Shape of metrics : ',metrics.shape,'\\t','Shape of bottlenecks : ',bottlenecks.shape) #42813\n",
    "print('Label cardinality = %.5f \\t Label density = %.5f' % (bottlenecks.sum(axis=1).mean(),bottlenecks.mean(axis=1).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics=scale_metrics(metrics, MinMaxScaler()) \n",
    "#print('Shape of metrics : ',metrics.shape,'\\t','Shape of bottlenecks : ',bottlenecks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SRV./: Free inodes in %', 'SRV./: Space utilization', 'SRV./: Used space', 'SRV./boot: Free inodes in %', 'SRV./boot: Space utilization', 'SRV./boot: Used space', 'SRV.Available memory', 'SRV.Available memory in %', 'SRV.CPU idle time', 'SRV.CPU iowait time', 'SRV.CPU softirq time', 'SRV.CPU system time', 'SRV.CPU user time', 'SRV.CPU utilization', 'SRV.Context switches per second', 'SRV.Free swap space', 'SRV.Free swap space in %', 'SRV.Interface enp0s8: Bits received', 'SRV.Interface enp0s8: Bits sent', 'SRV.Interrupts per second', 'SRV.Load average (15m avg)', 'SRV.Load average (1m avg)', 'SRV.Load average (5m avg)', 'SRV.Memory utilization', 'SRV.Number of processes', 'SRV.Number of running processes', 'GW1./: Free inodes in %', 'GW1./: Space utilization', 'GW1./: Used space', 'GW1./boot: Free inodes in %', 'GW1./boot: Space utilization', 'GW1./boot: Used space', 'GW1.Available memory', 'GW1.Available memory in %', 'GW1.CPU idle time', 'GW1.CPU iowait time', 'GW1.CPU softirq time', 'GW1.CPU system time', 'GW1.CPU user time', 'GW1.CPU utilization', 'GW1.Context switches per second', 'GW1.Free swap space', 'GW1.Free swap space in %', 'GW1.Interface enp0s8: Bits received', 'GW1.Interface enp0s8: Bits sent', 'GW1.Interrupts per second', 'GW1.Load average (15m avg)', 'GW1.Load average (1m avg)', 'GW1.Load average (5m avg)', 'GW1.Memory utilization', 'GW1.Number of processes', 'GW1.Number of running processes', 'GW11./: Free inodes in %', 'GW11./: Space utilization', 'GW11./: Used space', 'GW11./boot: Free inodes in %', 'GW11./boot: Space utilization', 'GW11./boot: Used space', 'GW11.Available memory', 'GW11.Available memory in %', 'GW11.CPU idle time', 'GW11.CPU iowait time', 'GW11.CPU softirq time', 'GW11.CPU system time', 'GW11.CPU user time', 'GW11.CPU utilization', 'GW11.Context switches per second', 'GW11.Free swap space', 'GW11.Free swap space in %', 'GW11.Interface enp0s8: Bits received', 'GW11.Interface enp0s8: Bits sent', 'GW11.Interrupts per second', 'GW11.Load average (15m avg)', 'GW11.Load average (1m avg)', 'GW11.Load average (5m avg)', 'GW11.Memory utilization', 'GW11.Number of processes', 'GW11.Number of running processes', 'GW111./: Free inodes in %', 'GW111./: Space utilization', 'GW111./: Used space', 'GW111./boot: Free inodes in %', 'GW111./boot: Space utilization', 'GW111./boot: Used space', 'GW111.Available memory', 'GW111.Available memory in %', 'GW111.CPU idle time', 'GW111.CPU iowait time', 'GW111.CPU softirq time', 'GW111.CPU system time', 'GW111.CPU user time', 'GW111.CPU utilization', 'GW111.Context switches per second', 'GW111.Free swap space', 'GW111.Free swap space in %', 'GW111.Interface enp0s8: Bits received', 'GW111.Interface enp0s8: Bits sent', 'GW111.Interrupts per second', 'GW111.Load average (15m avg)', 'GW111.Load average (1m avg)', 'GW111.Load average (5m avg)', 'GW111.Memory utilization', 'GW111.Number of processes', 'GW111.Number of running processes']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['GW1.cpu', 'GW1.diskio', 'GW1.diskspace', 'GW1.memory', 'GW1.network delay', 'GW1.network packet corrupt', 'GW1.network packet duplicate', 'GW1.network packet loss', 'GW11.cpu', 'GW11.diskio', 'GW11.diskspace', 'GW11.memory', 'GW11.network delay', 'GW11.network packet corrupt', 'GW11.network packet duplicate', 'GW11.network packet loss', 'GW111.cpu', 'GW111.diskio', 'GW111.diskspace', 'GW111.memory', 'GW111.network delay', 'GW111.network packet corrupt', 'GW111.network packet duplicate', 'GW111.network packet loss', 'SRV.cpu', 'SRV.diskio', 'SRV.diskspace', 'SRV.memory', 'SRV.network delay', 'SRV.network packet corrupt', 'SRV.network packet duplicate', 'SRV.network packet loss']\n"
     ]
    }
   ],
   "source": [
    "metric_names, bottleneck_names = list(metrics.columns), list(bottlenecks.columns)\n",
    "print(metric_names)\n",
    "print(100*'-')\n",
    "print(bottleneck_names)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt_all_data(metrics)\n",
    "if save:\n",
    "    fig.savefig(fig_path + \"monitored.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottlenecks.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29110, 104), (29110, 32), (9704, 104), (9704, 32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, o = 10, 0\n",
    "train_indexes, test_indexes = next(CV.split(metrics, bottlenecks))\n",
    "X_train, y_train = metrics.iloc[train_indexes, :], bottlenecks.iloc[train_indexes, :]\n",
    "X_test, y_test = metrics.iloc[test_indexes, :], bottlenecks.iloc[test_indexes, :]\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Feature extraction started ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 8% Complete\n",
       "              <p/>            \n",
       "              <progress\n",
       "                  value='252'\n",
       "                  max='2911',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  252\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tsfel\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.util import view_as_windows\n",
    "import warnings\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(metrics, bottlenecks, test_size=0.25, random_state=42)\n",
    "cfg = tsfel.get_features_by_domain(domain='temporal')\n",
    "X_train = tsfel.time_series_features_extractor(cfg, X_train, window_size=w, overlap=o) \n",
    "X_test = tsfel.time_series_features_extractor(cfg, X_test, window_size=w, overlap=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stride_axis0(a, L, overlap):\n",
    "    overlap = int(overlap * L)\n",
    "    if L == overlap:\n",
    "        raise Exception(\"Overlap arg must be smaller than length of windows\")\n",
    "    S = L - overlap\n",
    "    nd0 = ((len(a) - L) // S) + 1\n",
    "    if nd0 * S - S != len(a) - L:\n",
    "        warnings.warn(\"Not all elements were covered\")\n",
    "    a = view_as_windows(a, (L, a.shape[1]), step=S)[:, 0, :, :]\n",
    "    a = np.sum(a, axis=1)\n",
    "    a[a > 1] = 1\n",
    "    return a\n",
    "\n",
    "y_train = stride_axis0(y_train.values, w, o)\n",
    "y_test = stride_axis0(y_test.values, w, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(0.0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Handling eventual missing values from the feature extraction\n",
    "X_train = fill_missing_values(X_train)\n",
    "X_test = fill_missing_values(X_test)\n",
    "\n",
    "# Highly correlated features are removed\n",
    "corr_features = tsfel.correlated_features(X_train)\n",
    "X_train.drop(corr_features, axis=1, inplace=True)\n",
    "X_test.drop(corr_features, axis=1, inplace=True)\n",
    "\n",
    "# Remove low variance features\n",
    "selector = VarianceThreshold()\n",
    "X_train = selector.fit_transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Normalising Features\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "nX_train = min_max_scaler.fit_transform(X_train)\n",
    "nX_test = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(X_train).sum(),np.isnan(y_train).sum(),np.isnan(X_test).sum(),np.isnan(y_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nX_train.shape, y_train.shape, nX_test.shape , y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test, y_pred):\n",
    "    a = accuracy_score(y_test, y_pred)\n",
    "    m = user_defined_matthews_corrcoef(y_test, y_pred)\n",
    "    rest = {'Subset Accuracy': round(a, ROUND), 'MCC':round(m, ROUND)}\n",
    "    print(rest)\n",
    "    return rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "def train_and_plot(X_train, y_train, X_test, y_test):\n",
    "    for clf_name, clf in CLASSIFIERS.items():\n",
    "        train_x, train_y = np.copy(X_train), np.copy(y_train)\n",
    "        test_x, test_y = np.copy(X_test), np.copy(y_test)\n",
    "        print(80*'-')\n",
    "        print('#',clf_name.ljust(16), end=' ')\n",
    "        start=time.time()\n",
    "        clf.fit(train_x, train_y)\n",
    "        tt = time.time()-start\n",
    "        print('>','fit_time:',tt/60,'minutes') if tt > 60  else print('>','time:',tt,'secondes')\n",
    "        y_pred = clf.predict(test_x)\n",
    "        y_pred_proba = clf.predict_proba(test_x)\n",
    "        if not hasattr(y_pred, 'toarray'):\n",
    "            y_pred = sparse.csr_matrix(y_pred)\n",
    "        results[clf_name]=print_metrics(test_y, y_pred.toarray())\n",
    "        results[clf_name]['fit_time']=round(tt, ROUND)\n",
    "        #fig = plt_roc_auc(clf_name, y_pred_proba, test_y, bottleneck_names)\n",
    "        #fig.savefig(FIG_PATH + clf_name +\"_roc_curve.pdf\", bbox_inches='tight')\n",
    "    return pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf = RandomForestClassifier()\n",
    "print(80*'-')\n",
    "print('#','RandomForestClassifier', end=' ')\n",
    "start=time.time()\n",
    "clf.fit(nX_train, y_train)\n",
    "tt = time.time()-start\n",
    "print('>','fit_time:',tt/60,'minutes') if tt > 60  else print('>','time:',tt,'secondes')\n",
    "y_pred = clf.predict(nX_test)\n",
    "y_pred_proba = clf.predict_proba(nX_test)\n",
    "if not hasattr(y_pred, 'toarray'):\n",
    "    y_pred = sparse.csr_matrix(y_pred)\n",
    "    print_metrics(y_test, y_pred.toarray())\n",
    "print(classification_report(y_test, y_pred.toarray(), target_names=bottleneck_names))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# test prediction\n",
    "def test_predic(pick, clf):\n",
    "    test_data=nX_test[pick:pick+1,:]\n",
    "    print('x shape',test_data.shape)   \n",
    "    true_data = y_test[pick:pick+1,:][0]\n",
    "    print('y shape',true_data.shape)\n",
    "    prediction_data= clf.predict(test_data)[0]\n",
    "    print('pred shape',prediction_data.shape)\n",
    "    print(80*'-')\n",
    "    print('ytrue=',true_data)\n",
    "    print('ypred=',prediction_data)\n",
    "    true_data_class = [bottleneck_names[i] for i in range(len(bottleneck_names)) if true_data[i]>0]  \n",
    "    prediction_data_class = [bottleneck_names[i] for i in range(len(bottleneck_names)) if prediction_data[i]>0]\n",
    "    print('true class =', true_data_class, '| num. of labels =',len(true_data_class))\n",
    "    print(80*'-')\n",
    "    print('pred class=', prediction_data_class, '| num. of labels =',len(prediction_data_class))\n",
    "pick=0\n",
    "test_predic(pick, classifier)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plot_number_of_instance(bottlenecks)\n",
    "if save:\n",
    "    fig.savefig(fig_path + \"Number_of_instance_with_a_class_label.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fig = plt_corr_metrics(metrics, c3='w', method='spearman')\n",
    "if save:\n",
    "    fig.savefig(fig_path + \"Correlation in Metrics.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fig = plt_corr_bottlenecks(bottlenecks, c3='w', method='spearman')\n",
    "if save:\n",
    "    fig.savefig(fig_path + \"Correlation in Bottlenecks.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
